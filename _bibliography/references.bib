@inproceedings{chen2025berds,
  title={Open-World Evaluation for Retrieving Diverse Perspectives},
  author={Chen, Hung-Ting and Choi, Eunsol},
  booktitle={Proceedings of the 2025 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  year={2025},
  organization={Association for Computational Linguistics},
  url={https://arxiv.org/abs/2409.18110},
  website={https://timchen0618.github.io/berds/},
  abstract={We propose a new evaluation framework for retrieving diverse perspectives in open-world settings. We present BERDS (Benchmarking Evaluation for Retrieving Diverse Sources), which addresses the challenge of evaluating retrieval systems when the space of valid perspectives is not pre-defined.}
}

@inproceedings{chen2024understanding,
  title={Understanding Retrieval Augmentation for Long-Form Question Answering},
  author={Chen, Hung-Ting and Xu, Fangyuan and Arora, Shane A. and Choi, Eunsol},
  booktitle={Proceedings of the Conference on Language Modeling},
  year={2024},
  organization={COLM},
  url={https://arxiv.org/abs/2310.12150},
  abstract={This paper provides a comprehensive analysis of retrieval augmentation for long-form question answering. We examine how retrieval augmentation affects model performance across different types of questions and identify key factors that determine its effectiveness.}
}

@inproceedings{gao2023continually,
  title={Continually Improving Extractive QA via Human Feedback},
  author={Gao, Ge and Chen, Hung-Ting and Artzi, Yoav and Choi, Eunsol},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={5902--5919},
  year={2023},
  organization={Association for Computational Linguistics},
  url={https://arxiv.org/abs/2305.12473},
  abstract={This paper presents a framework for continually improving extractive question answering systems through human feedback. We demonstrate how models can learn from corrective feedback to improve their performance over time.}
}

@inproceedings{chen2022rich,
  title={Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating Models to Reflect Conflicting Evidence},
  author={Chen, Hung-Ting and Zhang, Michael J.Q. and Choi, Eunsol},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={2292--2307},
  year={2022},
  organization={Association for Computational Linguistics},
  url={https://aclanthology.org/2022.emnlp-main.146/},
  abstract={This paper addresses the challenge of knowledge conflicts that arise when models have access to rich, diverse knowledge sources. We propose methods for recalibrating models to appropriately handle conflicting evidence and reflect uncertainty in their predictions.}
}

@article{arora2024calmqa,
  title={CaLMQA: Exploring culturally specific long-form question answering across 23 languages},
  author={Arora, Shane and Karpinska, Marzena and Chen, Hung-Ting and Bhattacharjee, Ipsita and Iyyer, Mohit and Choi, Eunsol},
  journal={arXiv preprint arXiv:2406.17761},
  year={2024},
  url={https://arxiv.org/abs/2406.17761},
  abstract={This paper introduces CaLMQA, a benchmark for evaluating long-form question answering systems on culturally specific questions across 23 languages. We analyze how different models handle cultural nuances and language-specific knowledge.}
} 